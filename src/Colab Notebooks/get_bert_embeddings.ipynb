{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"get_bert_embeddings.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1qo8FqiKcl6nTCNDoYiZ5KwO4zl-4_af1","authorship_tag":"ABX9TyPSXxok8bHxJnanrqD8atoD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"47a76ece45f14ed9a4afa71ad9b3c91b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_13a54539fd7f413084fe1186ff8b3f70","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d695c2a083c845ff92e763c62ebfa3ea","IPY_MODEL_a83fd7e84c3a46fc9687d2b5274c7f4b"]}},"13a54539fd7f413084fe1186ff8b3f70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d695c2a083c845ff92e763c62ebfa3ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_be4372e5427748cc8692594065eaf071","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d9b7285ce5a847f4931c49a17ca28948"}},"a83fd7e84c3a46fc9687d2b5274c7f4b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2210b2526ed347b09a906e63fa4c92a4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 577kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3b1e73bf68654d52b07b8190bd53580b"}},"be4372e5427748cc8692594065eaf071":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d9b7285ce5a847f4931c49a17ca28948":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2210b2526ed347b09a906e63fa4c92a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3b1e73bf68654d52b07b8190bd53580b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"AoQ6iMxAYSBD","colab_type":"text"},"source":["# BERT embedding creation for Research Project 32934 on Google Colab\n","* This note book was used to create BERT embeddings for the datasets.\n","\n","* It can be used without a mounted google drive however its not recommended.\n","\n","* The library used for getting the BERT embeddings is called Bert-as-a-service. It takes a saved BERT model and starts up an optimized encoding server which can be used to encode any number of sentences.\n","\n","* The saved weights used for this can be downloaded from https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n","It is recommended to store these on Google Drive for persistent storage.\n","\n","* The datasets can also be stored on google drive and the Paths in the cell below can be changed accordingly.\n","\n","* The code below reads the JSON file and loads it in a pandas dataframe.\n","At the end, the entire train and test dataframes are pickled and saved at the path specified.\n","\n","* A max sequence length of 256 was chosen as anything larger than that would not give results (computational limitations?).\n","\n","**NOTE:** This notebook requires a different tensorflow version than the rest of the source code. This was part of the reason why its run on colab.\n"]},{"cell_type":"code","metadata":{"id":"Pp139-eJU9vk","colab_type":"code","colab":{}},"source":["PATH_TO_TRAIN_SET = '/content/drive/My Drive/temp_datasets/combined-train.json'\n","PATH_TO_TEST_SET = '/content/drive/My Drive/temp_datasets/combined-test.json'\n","\n","PATH_TO_SAVE_TRAIN_EMBEDS = '/content/drive/My Drive/temp_datasets/clpsych16_train_bert_embeds.pkl'\n","PATH_TO_SAVE_TEST_EMBEDS = '/content/drive/My Drive/temp_datasets/clpsych16_test_bert_embeds.pkl'\n","\n","PATH_TO_SAVED_BERT = '/content/drive/My Drive/temp_datasets/uncased_L-12_H-768_A-12'\n","# PATH_TO_SAVED_BERT = '/content/drive/My Drive/temp_datasets/uncased_L-24_H-1024_A-16'\n","\n","MAX_LEN = 256"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uen5ot4wQNQv","colab_type":"code","outputId":"d0b64f9d-5d7e-4540-c831-e3f2fa336952","executionInfo":{"status":"ok","timestamp":1591734520861,"user_tz":-480,"elapsed":3078,"user":{"displayName":"Vedant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGzEqOWNtZoEoJEq0c0x-O2oEMGciUkRUlK4e8=s64","userId":"16012316052717052545"}},"colab":{"base_uri":"https://localhost:8080/","height":302}},"source":["!nvidia-smi"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Tue Jun  9 20:28:40 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-dYUzLp-Mkk7","colab_type":"code","outputId":"bbdc42b6-6e03-4818-80f5-5de0bda1870f","executionInfo":{"status":"ok","timestamp":1591733711697,"user_tz":-480,"elapsed":75478,"user":{"displayName":"Vedant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGzEqOWNtZoEoJEq0c0x-O2oEMGciUkRUlK4e8=s64","userId":"16012316052717052545"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["!nohup pip install bert-serving-client tensorflow-gpu==1.15.0 transformers\n","!nohup pip install -U bert-serving-server[http]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["nohup: ignoring input and appending output to 'nohup.out'\n","nohup: ignoring input and appending output to 'nohup.out'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dd_CO9ynNf3E","colab_type":"code","colab":{}},"source":["import json\n","from bs4 import BeautifulSoup\n","from pprint import pprint\n","import pandas as pd\n","import re\n","\n","\n","def clean_text(raw_text: str):\n","    if raw_text is None:\n","        return ''\n","\n","    soup = BeautifulSoup(raw_text, features=\"html.parser\")\n","    raw_text = soup.get_text()\n","    raw_text = raw_text.replace('\\n', ' ').replace('\\xa0', ' ')\n","    return raw_text\n","\n","\n","def read_json_as_df(path: str) -> pd.DataFrame:\n","    json_data = []\n","\n","    with open(path, 'r', encoding='utf-8') as file:\n","\n","        for line in file:\n","            data = json.loads(line)\n","            json_data.append([clean_text(data['post'].get('body', None)),\n","                              data['priority']])\n","\n","    df = pd.DataFrame(data=json_data, columns=('text', 'priority'))\n","\n","    return df\n","\n","train_df = read_json_as_df(PATH_TO_TRAIN_SET)\n","test_df = read_json_as_df(PATH_TO_TEST_SET)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S2d2AQZPIu0X","colab_type":"code","outputId":"e3deb310-7f3c-4cf7-9909-0944eeebcb06","executionInfo":{"status":"ok","timestamp":1591733727977,"user_tz":-480,"elapsed":87011,"user":{"displayName":"Vedant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGzEqOWNtZoEoJEq0c0x-O2oEMGciUkRUlK4e8=s64","userId":"16012316052717052545"}},"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["47a76ece45f14ed9a4afa71ad9b3c91b","13a54539fd7f413084fe1186ff8b3f70","d695c2a083c845ff92e763c62ebfa3ea","a83fd7e84c3a46fc9687d2b5274c7f4b","be4372e5427748cc8692594065eaf071","d9b7285ce5a847f4931c49a17ca28948","2210b2526ed347b09a906e63fa4c92a4","3b1e73bf68654d52b07b8190bd53580b"]}},"source":["import transformers\n","tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased',\n","                                                             do_lower_case=True)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47a76ece45f14ed9a4afa71ad9b3c91b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iMPYe6hxIupW","colab_type":"code","colab":{}},"source":["import numpy as np\n","from tqdm import tqdm\n","\n","train_df['tokenized_len'] = np.array([len(tokenizer.tokenize(sent)) for sent in train_df.text])\n","test_df['tokenized_len'] = np.array([len(tokenizer.tokenize(sent)) for sent in test_df.text])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xjQEwmgl3BVp","colab_type":"code","outputId":"f47d8a8a-ad32-41f7-e315-c30def23da20","executionInfo":{"status":"ok","timestamp":1591733736593,"user_tz":-480,"elapsed":93451,"user":{"displayName":"Vedant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGzEqOWNtZoEoJEq0c0x-O2oEMGciUkRUlK4e8=s64","userId":"16012316052717052545"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["max(train_df.tokenized_len)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1793"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"lBO0vBklMue4","colab_type":"code","colab":{}},"source":["!nohup bert-serving-start -pooling_layer -4 -3 -2 -model_dir=\"{PATH_TO_SAVED_BERT}\" -max_seq_len={MAX_LEN} > out.txt 2>&1 &"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GhUzqjyJNq7C","colab_type":"code","colab":{}},"source":["from bert_serving.client import BertClient\n","bc = BertClient()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Mu8_v36O0an","colab_type":"code","colab":{}},"source":["train_df.text = train_df.text.str.strip()\n","train_df = train_df[train_df.text != '']\n","\n","# test_df.text = test_df.text.str.strip()\n","test_df = test_df[test_df.text != '']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xkzdyNHYH1Be","colab_type":"code","colab":{}},"source":["def get_chunk_embeds(sents):\n","    embeddings = bc.encode(sents)\n","    return np.mean(embeddings, axis=0)\n","\n","def chunks(lst, n):\n","    for i in range(0, len(lst), n):\n","        yield lst[i:i + n]\n","\n","def split_sentences(sents, LEN):\n","    sents = tokenizer.tokenize(sents)\n","    sents = list(chunks(sents, LEN))\n","    return [' '.join(sent) for sent in sents]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XhqR2nbPHNU_","colab_type":"code","colab":{}},"source":["%%time\n","\n","short_train_df = train_df[train_df.tokenized_len <= MAX_LEN]\n","short_train_embeds = bc.encode(short_train_df.text.values.tolist())\n","short_train_df.insert(loc=0, value=[embed for embed in short_train_embeds], column='embeds')\n","\n","\n","long_train_df = train_df[train_df.tokenized_len > MAX_LEN]\n","long_train_sents = [split_sentences(sent, MAX_LEN) for sent in long_train_df.text.values]\n","long_train_embeds = [get_chunk_embeds(sents) for sents in tqdm(long_train_sents)]\n","long_train_df.insert(loc=0, value=long_train_embeds, column='embeds')\n","\n","short_test_df = test_df[test_df.tokenized_len <= MAX_LEN]\n","short_test_embeds = bc.encode(short_test_df.text.values.tolist())\n","short_test_df.insert(loc=0, value=[embed for embed in short_test_embeds], column='embeds')\n","\n","long_test_df = test_df[test_df.tokenized_len > MAX_LEN]\n","long_test_sents = [split_sentences(sent, MAX_LEN) for sent in long_test_df.text.values]\n","long_test_embeds = [get_chunk_embeds(sents) for sents in tqdm(long_test_sents)]\n","long_test_df.insert(loc=0, value=long_test_embeds, column='embeds')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fEHePQ-Lcvad","colab_type":"code","colab":{}},"source":["new_train_df = pd.concat([short_train_df, long_train_df])\n","new_test_df = pd.concat([short_test_df, long_test_df])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1BkPPUyGkf1b","colab_type":"code","colab":{}},"source":["assert new_train_df[new_train_df.embeds.isnull()].values.tolist() is not None\n","assert new_test_df[new_test_df.embeds.isnull()].values.tolist() is not None\n","\n","assert new_train_df.shape[0] == train_df.shape[0]\n","assert new_test_df.shape[0] == test_df.shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JJ62DbSKZ21z","colab_type":"code","outputId":"38c1da43-f433-42b6-9519-3b3df04ef20e","executionInfo":{"status":"ok","timestamp":1591680441239,"user_tz":-480,"elapsed":11094,"user":{"displayName":"Vedant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGzEqOWNtZoEoJEq0c0x-O2oEMGciUkRUlK4e8=s64","userId":"16012316052717052545"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["new_train_df.embeds[0].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2304,)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"4uz3CPMgazeQ","colab_type":"code","colab":{}},"source":["import pickle\n","pickle.dump(new_train_df, open(PATH_TO_SAVE_TRAIN_EMBEDS, 'wb'))\n","pickle.dump(new_test_df, open(PATH_TO_SAVE_TEST_EMBEDS, 'wb'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W95ri_icdgt4","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}