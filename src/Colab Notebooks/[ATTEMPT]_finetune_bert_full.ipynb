{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"name":"[ATTEMPT]_finetune_bert_full.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"TLLu81ZYeKno","colab_type":"text"},"source":["# Attempt to fine tune BERT with the VERY limited data available\n","\n","**Result:** The code works but will require more work to get embeddings of longer texts."]},{"cell_type":"code","metadata":{"id":"cX7qviwH7mhl","colab_type":"code","outputId":"c34517a4-9773-4e54-8a29-effa62e22b6e","executionInfo":{"status":"ok","timestamp":1590066533458,"user_tz":-480,"elapsed":2648,"user":{"displayName":"Vedant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGzEqOWNtZoEoJEq0c0x-O2oEMGciUkRUlK4e8=s64","userId":"16012316052717052545"}},"colab":{"base_uri":"https://localhost:8080/","height":302}},"source":["!nvidia-smi"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Thu May 21 13:08:51 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   52C    P0    33W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9jUpWoq8xkOP","colab_type":"code","outputId":"ecc23e5b-56b1-40e5-c699-673ef0cfe0c5","executionInfo":{"status":"ok","timestamp":1590066536438,"user_tz":-480,"elapsed":5620,"user":{"displayName":"Vedant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGzEqOWNtZoEoJEq0c0x-O2oEMGciUkRUlK4e8=s64","userId":"16012316052717052545"}},"colab":{"base_uri":"https://localhost:8080/","height":322}},"source":["!pip install transformers"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.9.1)\n","Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rs7O8oeBq9gN","colab_type":"code","outputId":"3682494d-4e0f-46bd-f8db-63071cb9ed6e","executionInfo":{"status":"ok","timestamp":1590066536439,"user_tz":-480,"elapsed":5613,"user":{"displayName":"Vedant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGzEqOWNtZoEoJEq0c0x-O2oEMGciUkRUlK4e8=s64","userId":"16012316052717052545"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HzZQW1uGxXv2","colab_type":"code","colab":{}},"source":["import json\n","from bs4 import BeautifulSoup\n","from pprint import pprint\n","import pandas as pd\n","import re\n","\n","def clean_text(raw_text: str):\n","    if raw_text is None:\n","        return ''\n","\n","    soup = BeautifulSoup(raw_text, features=\"html.parser\")\n","    raw_text = soup.get_text()\n","    raw_text = raw_text.replace('\\n', ' ').replace('\\xa0', ' ')\n","    return raw_text\n","\n","\n","def read_json_as_df(path: str) -> pd.DataFrame:\n","    json_data = []\n","\n","    with open(path, 'r', encoding='utf-8') as file:\n","\n","        for line in file:\n","            data = json.loads(line)\n","            json_data.append([clean_text(data['post'].get('body', None)),\n","                              data['priority']])\n","\n","    df = pd.DataFrame(data=json_data, columns=('text', 'priority'))\n","\n","    return df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WTJzG9RnxXv5","colab_type":"code","colab":{}},"source":["import random\n","import numpy as np\n","import pandas as pd\n","import transformers\n","import time\n","import datetime\n","from tqdm import tqdm\n","\n","import torch\n","\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QQL3mdOjxXv7","colab_type":"code","colab":{}},"source":["MAX_LENGTH = 512\n","BATCH_SIZE = 16\n","EPOCHS = 3\n","\n","label_mapping = {\n","    'green': 0,\n","    'amber': 1,\n","    'escalate': 2,\n","    'red': 3\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1oKiDyp7xXv9","colab_type":"code","colab":{}},"source":["tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased',\n","                                                       do_lower_case=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hhUbXs7XxXwA","colab_type":"code","colab":{}},"source":["train_df = read_json_as_df('/content/drive/My Drive/temp_datasets/combined-train.json')\n","test_df = read_json_as_df('/content/drive/My Drive/temp_datasets/combined-test.json')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ohF5zS7sxXwC","colab_type":"code","colab":{}},"source":["train_df['sentence_len'] = np.array([len(sent) for sent in train_df.text])\n","test_df['sentence_len'] = np.array([len(sent) for sent in test_df.text])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rVHpIdzlxXwE","colab_type":"code","colab":{}},"source":["train_df['tokenized_len'] = np.array([len(tokenizer.tokenize(sent)) for sent in train_df.text])\n","test_df['tokenized_len'] = np.array([len(tokenizer.tokenize(sent)) for sent in test_df.text])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wQJJIehmxXwG","colab_type":"code","colab":{}},"source":["train_df = train_df[train_df.tokenized_len < 510]\n","test_df = test_df[test_df.tokenized_len < 510]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tT5dBbXVxXwI","colab_type":"code","colab":{}},"source":["def tokenize(sentences, tokenizer):\n","    input_ids, input_masks = [],[]\n","    for sentence in tqdm(sentences):\n","        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=MAX_LENGTH, pad_to_max_length=True, \n","                                             return_attention_mask=True, return_token_type_ids=False)\n","        input_ids.append(inputs['input_ids'])\n","        input_masks.append(inputs['attention_mask'])\n","        \n","    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HDZnXsUPxXwK","colab_type":"code","outputId":"ef1d0703-26c7-411c-b5b7-56c2e6223fa2","executionInfo":{"status":"ok","timestamp":1590066561768,"user_tz":-480,"elapsed":30874,"user":{"displayName":"Vedant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGzEqOWNtZoEoJEq0c0x-O2oEMGciUkRUlK4e8=s64","userId":"16012316052717052545"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["train_input_ids, train_input_masks = tokenize(train_df.text, tokenizer)\n","test_input_ids, test_input_masks = tokenize(test_df.text, tokenizer)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 6301/6301 [00:07<00:00, 793.21it/s]\n","100%|██████████| 386/386 [00:00<00:00, 613.75it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"p5sCQP3pxXwN","colab_type":"code","colab":{}},"source":["train_input_ids = torch.tensor(train_input_ids)\n","train_input_masks = torch.tensor(train_input_masks)\n","\n","test_input_ids = torch.tensor(test_input_ids)\n","test_input_masks = torch.tensor(test_input_masks)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q1G4_627xXwP","colab_type":"code","colab":{}},"source":["train_labels = torch.tensor(train_df.priority.map(label_mapping).values)\n","test_labels = torch.tensor(test_df.priority.map(label_mapping).values)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tW6Mmx0pxXwT","colab_type":"code","colab":{}},"source":["train_dataset = torch.utils.data.TensorDataset(train_input_ids,\n","                                               train_input_masks,\n","                                               train_labels)\n","\n","test_dataset = torch.utils.data.TensorDataset(test_input_ids,\n","                                               test_input_masks,\n","                                               test_labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E03aZJdgxXwV","colab_type":"code","colab":{}},"source":["# train_size = int(0.9 * len(train_dataset))\n","# val_size = len(train_dataset) - train_size\n","\n","# train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n","\n","# print(f'Train set size: {train_size}\\nValid set size: {val_size}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kycGhJhYxXwX","colab_type":"code","colab":{}},"source":["train_dataloader = torch.utils.data.DataLoader(train_dataset,\n","                                               sampler=torch.utils.data.RandomSampler(train_dataset),\n","                                               batch_size=BATCH_SIZE)\n","\n","# validation_dataloader = torch.utils.data.DataLoader(val_dataset,\n","#                                              sampler=torch.utils.data.RandomSampler(val_dataset),\n","#                                              batch_size=BATCH_SIZE)\n","\n","test_dataloader = torch.utils.data.DataLoader(test_dataset,\n","                                             sampler=torch.utils.data.SequentialSampler(test_dataset),\n","                                             batch_size=BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"jupyter":{"outputs_hidden":true},"id":"ZrW3cjHyxXwZ","colab_type":"code","colab":{}},"source":["model = transformers.BertForSequenceClassification.from_pretrained('bert-base-uncased',\n","                                                                   num_labels=4,\n","                                                                   output_attentions=False,\n","                                                                   output_hidden_states=False)\n","\n","model.cuda()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yo_6gzuTxXwc","colab_type":"code","outputId":"4b3d7fa8-5d64-48d8-bac7-d0470b36d880","executionInfo":{"status":"ok","timestamp":1590066569308,"user_tz":-480,"elapsed":38362,"user":{"displayName":"Vedant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGzEqOWNtZoEoJEq0c0x-O2oEMGciUkRUlK4e8=s64","userId":"16012316052717052545"}},"colab":{"base_uri":"https://localhost:8080/","height":605}},"source":["params = list(model.named_parameters())\n","\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The BERT model has 201 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","bert.embeddings.word_embeddings.weight                  (30522, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layer ====\n","\n","bert.pooler.dense.weight                                  (768, 768)\n","bert.pooler.dense.bias                                        (768,)\n","classifier.weight                                           (4, 768)\n","classifier.bias                                                 (4,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iJxa2asNxXwe","colab_type":"code","colab":{}},"source":["optimizer = transformers.AdamW(model.parameters(),\n","                               lr=5e-5,\n","                               eps=1e-8)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NssbeG1XxXwf","colab_type":"code","colab":{}},"source":["total_steps = len(train_dataloader) * EPOCHS\n","\n","scheduler = transformers.get_linear_schedule_with_warmup(optimizer,\n","                                                         num_warmup_steps=0,\n","                                                         num_training_steps=total_steps)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MnL1iFUmxXwh","colab_type":"code","colab":{}},"source":["def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"jupyter":{"outputs_hidden":true},"id":"Vo6hVVGPxXwj","colab_type":"code","outputId":"a5f90a5e-0159-49bb-a427-b79c68624e66","executionInfo":{"status":"ok","timestamp":1590067556753,"user_tz":-480,"elapsed":1025782,"user":{"displayName":"Vedant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGzEqOWNtZoEoJEq0c0x-O2oEMGciUkRUlK4e8=s64","userId":"16012316052717052545"}},"colab":{"base_uri":"https://localhost:8080/","height":890}},"source":["seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","training_stats = []\n","\n","total_t0 = time.time()\n","\n","for epoch_i in range(0, EPOCHS):\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, EPOCHS))\n","    print('Training...')\n","    \n","    t0 = time.time()\n","\n","    total_train_loss = 0\n","\n","    model.train()\n","\n","    for step, batch in enumerate(train_dataloader):\n","        \n","        if step % 40 == 0 and not step == 0:\n","\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","            \n","        b_input_ids = batch[0].long().to(device)\n","        b_input_mask = batch[1].long().to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        model.zero_grad()        \n","        \n","        loss, logits = model(b_input_ids, \n","                             token_type_ids=None, \n","                             attention_mask=b_input_mask, \n","                             labels=b_labels)\n","        \n","        total_train_loss += loss.item()\n","        \n","        loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        \n","        optimizer.step()\n","        \n","        scheduler.step()\n","        \n","    avg_train_loss = total_train_loss / len(train_dataloader)\n","\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","    \n","    # print(\"\")\n","    # print(\"Running Validation...\")\n","    \n","    # t0 = time.time()\n","    \n","    # model.eval()\n","    \n","    # total_eval_accuracy = 0\n","    # total_eval_loss = 0\n","    # nb_eval_steps = 0\n","    \n","    # for batch in validation_dataloader:\n","        \n","    #     b_input_ids = batch[0].long().to(device)\n","    #     b_input_mask = batch[1].long().to(device)\n","    #     b_labels = batch[2].to(device)\n","        \n","    #     with torch.no_grad():        \n","            \n","    #         (loss, logits) = model(b_input_ids, \n","    #                                token_type_ids=None, \n","    #                                attention_mask=b_input_mask,\n","    #                                labels=b_labels)\n","       \n","    # total_eval_loss += loss.item() \n","    # logits = logits.detach().cpu().numpy()\n","    # label_ids = b_labels.to('cpu').numpy()\n","    \n","    # total_eval_accuracy += flat_accuracy(logits, label_ids)\n","    \n","    # avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    # print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # validation_time = format_time(time.time() - t0)\n","    \n","    # print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    # print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # training_stats.append(\n","    #     {\n","    #         'epoch': epoch_i + 1,\n","    #         'Training Loss': avg_train_loss,\n","    #         'Valid. Loss': avg_val_loss,\n","    #         'Valid. Accur.': avg_val_accuracy,\n","    #         'Training Time': training_time,\n","    #         'Validation Time': validation_time\n","    #     }\n","    # )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n","    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 3 ========\n","Training...\n"],"name":"stdout"},{"output_type":"stream","text":["/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha)\n"],"name":"stderr"},{"output_type":"stream","text":["  Batch    40  of    394.    Elapsed: 0:00:33.\n","  Batch    80  of    394.    Elapsed: 0:01:07.\n","  Batch   120  of    394.    Elapsed: 0:01:40.\n","  Batch   160  of    394.    Elapsed: 0:02:14.\n","  Batch   200  of    394.    Elapsed: 0:02:47.\n","  Batch   240  of    394.    Elapsed: 0:03:21.\n","  Batch   280  of    394.    Elapsed: 0:03:54.\n","  Batch   320  of    394.    Elapsed: 0:04:27.\n","  Batch   360  of    394.    Elapsed: 0:05:01.\n","\n","  Average training loss: 0.72\n","  Training epcoh took: 0:05:29\n","\n","======== Epoch 2 / 3 ========\n","Training...\n","  Batch    40  of    394.    Elapsed: 0:00:33.\n","  Batch    80  of    394.    Elapsed: 0:01:07.\n","  Batch   120  of    394.    Elapsed: 0:01:40.\n","  Batch   160  of    394.    Elapsed: 0:02:14.\n","  Batch   200  of    394.    Elapsed: 0:02:47.\n","  Batch   240  of    394.    Elapsed: 0:03:21.\n","  Batch   280  of    394.    Elapsed: 0:03:54.\n","  Batch   320  of    394.    Elapsed: 0:04:27.\n","  Batch   360  of    394.    Elapsed: 0:05:01.\n","\n","  Average training loss: 0.48\n","  Training epcoh took: 0:05:29\n","\n","======== Epoch 3 / 3 ========\n","Training...\n","  Batch    40  of    394.    Elapsed: 0:00:33.\n","  Batch    80  of    394.    Elapsed: 0:01:07.\n","  Batch   120  of    394.    Elapsed: 0:01:40.\n","  Batch   160  of    394.    Elapsed: 0:02:14.\n","  Batch   200  of    394.    Elapsed: 0:02:47.\n","  Batch   240  of    394.    Elapsed: 0:03:21.\n","  Batch   280  of    394.    Elapsed: 0:03:54.\n","  Batch   320  of    394.    Elapsed: 0:04:27.\n","  Batch   360  of    394.    Elapsed: 0:05:01.\n","\n","  Average training loss: 0.27\n","  Training epcoh took: 0:05:29\n","\n","Training complete!\n","Total training took 0:16:27 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XC_PLJ1GxXwn","colab_type":"code","colab":{}},"source":["model.eval()\n","\n","predictions, true_labels = [], []\n","\n","for batch in test_dataloader:\n","    \n","    batch = tuple(t.long().to(device) for t in batch)\n","    \n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    with torch.no_grad():\n","        \n","        outputs = model(b_input_ids, \n","                        token_type_ids=None,\n","                        attention_mask=b_input_mask)\n","        \n","    logits = outputs[0]\n","    \n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    \n","    predictions.append(logits)\n","    true_labels.append(label_ids)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kPH97WYPQnwy","colab_type":"code","colab":{}},"source":["from sklearn.metrics import classification_report"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yQHusJMhS4HY","colab_type":"code","colab":{}},"source":["flat_predictions = np.concatenate(predictions, axis=0)\n","\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","\n","flat_true_labels = np.concatenate(true_labels, axis=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zhhj8Bb4UpZE","colab_type":"code","colab":{}},"source":["inverted_label_mapping = {\n","    0: 'green',\n","    1: 'amber',\n","    2: 'escalate',\n","    3: 'red'\n","}\n","\n","flat_predictions = list(map(inverted_label_mapping.get, flat_predictions))\n","flat_true_labels = list(map(inverted_label_mapping.get, flat_true_labels))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CIUiTaIYTInA","colab_type":"code","outputId":"391d194a-2bc0-416d-b89a-12b25915eac4","executionInfo":{"status":"ok","timestamp":1590067563313,"user_tz":-480,"elapsed":1032309,"user":{"displayName":"Vedant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGzEqOWNtZoEoJEq0c0x-O2oEMGciUkRUlK4e8=s64","userId":"16012316052717052545"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["print(classification_report(y_true=flat_true_labels,\n","                            y_pred=flat_predictions))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","       amber       0.69      0.72      0.71       151\n","    escalate       0.44      0.25      0.32        16\n","       green       0.78      0.96      0.86       156\n","         red       0.58      0.24      0.34        63\n","\n","    accuracy                           0.72       386\n","   macro avg       0.62      0.54      0.56       386\n","weighted avg       0.70      0.72      0.69       386\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NNeqwqmvTf8C","colab_type":"code","outputId":"00ca251a-d771-4d12-e3cb-d368e54e0496","executionInfo":{"status":"ok","timestamp":1590067563314,"user_tz":-480,"elapsed":1032303,"user":{"displayName":"Vedant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGzEqOWNtZoEoJEq0c0x-O2oEMGciUkRUlK4e8=s64","userId":"16012316052717052545"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sklearn.metrics import f1_score\n","print('Macro avgd f1 score: ',\n","      f1_score(flat_true_labels,\n","               flat_predictions, \n","               labels=['escalate', 'red', 'amber'],\n","               average='macro'))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Macro avgd f1 score:  0.4541934232694569\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eg0Pmkjdibxe","colab_type":"code","outputId":"9f628f2d-6f60-48df-a37f-98898d3b7f54","executionInfo":{"status":"ok","timestamp":1590067563314,"user_tz":-480,"elapsed":1032296,"user":{"displayName":"Vedant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGzEqOWNtZoEoJEq0c0x-O2oEMGciUkRUlK4e8=s64","userId":"16012316052717052545"}},"colab":{"base_uri":"https://localhost:8080/","height":185}},"source":["def map_flagged(label):\n","    if label in ['escalate', 'red', 'amber']:\n","        return 'flagged'\n","    elif label == 'green':\n","        return 'green'\n","\n","flagged_ytest = list(map(map_flagged, flat_true_labels))\n","flagged_predictions = list(map(map_flagged, flat_predictions))\n","\n","print('Classification Report:\\n', classification_report(flagged_ytest, flagged_predictions))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Classification Report:\n","               precision    recall  f1-score   support\n","\n","     flagged       0.97      0.81      0.88       230\n","       green       0.78      0.96      0.86       156\n","\n","    accuracy                           0.87       386\n","   macro avg       0.87      0.89      0.87       386\n","weighted avg       0.89      0.87      0.87       386\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r_r_TFhfj1zU","colab_type":"code","outputId":"9518653d-b625-4d01-a277-af72266b5a4f","executionInfo":{"status":"ok","timestamp":1590067563315,"user_tz":-480,"elapsed":1032289,"user":{"displayName":"Vedant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGzEqOWNtZoEoJEq0c0x-O2oEMGciUkRUlK4e8=s64","userId":"16012316052717052545"}},"colab":{"base_uri":"https://localhost:8080/","height":185}},"source":["def map_urgent(label):\n","    if label in ['escalate', 'red']:\n","        return 'urgent'\n","    elif label in ['green', 'amber']:\n","        return 'non-urgent'\n","\n","urgent_ytest = list(map(map_urgent, flat_true_labels))\n","urgent_predictions = list(map(map_urgent, flat_predictions))\n","\n","print('Classification Report:\\n', classification_report(urgent_ytest, urgent_predictions))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Classification Report:\n","               precision    recall  f1-score   support\n","\n","  non-urgent       0.86      0.98      0.92       307\n","      urgent       0.86      0.38      0.53        79\n","\n","    accuracy                           0.86       386\n","   macro avg       0.86      0.68      0.72       386\n","weighted avg       0.86      0.86      0.84       386\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9V3fI5zmkAb5","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}